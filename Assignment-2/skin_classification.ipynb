{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin-classification.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KhPbgerlhCvF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " !pip install -U -q PyDrive ## you will have install for every colab session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7XBkCJGhFkC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1KdpgwPhIYK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "json_import = drive.CreateFile({'id':'1ONFNFcwp81mhJmTvBa-cdr9rtbh6j-NF'})\n",
        "json_import.GetContentFile('y_train.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "json_import = drive.CreateFile({'id':'1BoBts1RcOjWrs9ZynAwW74MgEhjMREiZ'})\n",
        "json_import.GetContentFile('y_test.npy')\n",
        "y_test = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5pRbde2jMUb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "260cc240-7596-4fa6-cf1e-5617a51209a7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523291856622,
          "user_tz": -330,
          "elapsed": 1508,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.shape,y_test.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1599, 1), (401, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "lUX3vIzzhcVY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "json_import = drive.CreateFile({'id':'1xRSfGO8G25lQ_4-cANtWYkm4DbX6IV9_'})\n",
        "json_import.GetContentFile('X_train.npy')\n",
        "X_train = np.load('X_train.npy')\n",
        "json_import = drive.CreateFile({'id':'1TmJmYnPm__-OrWOZhbSVyXW4Uzo175L8'})\n",
        "json_import.GetContentFile('X_test.npy')\n",
        "X_test = np.load('X_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CuK-8Bn2jVRs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4700044e-ff25-4279-927f-8d4f8168ac47",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523291869707,
          "user_tz": -330,
          "elapsed": 1481,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1599, 128, 128, 3), (401, 128, 128, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "_RmA33rSjeTk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e2a3a42d-e6a8-48c6-a201-458c45193e18",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523282343573,
          "user_tz": -330,
          "elapsed": 10722,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6dc4daac-9d12-462b-bb8f-ada848c10521\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6dc4daac-9d12-462b-bb8f-ada848c10521\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving resnet_classifier_ISIC.py to resnet_classifier_ISIC.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-0jJFI_2kg75",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from keras.layers import Add\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint\n",
        "import scipy.io as scio\n",
        "import numpy as np    \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import re\n",
        "from scipy.misc import imsave\n",
        "from scipy.misc import imresize\n",
        "from scipy import ndimage, misc\n",
        "from numpy import unravel_index\n",
        "from operator import sub\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kemt0eV1wEHE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = X_train.astype('float32')\n",
        "x_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7mziW9nnwOwI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_Ts1BPNwUj7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def initial_conv(Input):\n",
        "    x = Conv2D(16,kernel_size=(3,3),strides = (1,1),padding = 'same')(Input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KSHChhdwZLt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def expand_conv(Input, k=1, conv_no = 1,stride=1,dropout =0.0):\n",
        "    Initial = Input\n",
        "    x = Conv2D(32*k*conv_no,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(Input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(32*k*conv_no,kernel_size=(3,3),strides = (1,1),padding ='same')(x)\n",
        "    skip = Conv2D(32*k*conv_no,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(Input)\n",
        "    output = Add()([x,skip])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6bUcO5AxJq0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block1(Input, k = 1, stride = 1, dropout = 0.0):\n",
        "    Initial = Input \n",
        "    x = BatchNormalization()(Input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(32*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0.0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(32*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    output = Add()([x,Initial])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ju8ig-Ldwgec",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block2(Input, k = 1, stride = 1, dropout = 0.0):\n",
        "    Initial = Input \n",
        "    x = BatchNormalization()(Input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0.0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(64*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    output = Add()([x,Initial])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gOkCtUIXwlR8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block3(Input, k = 1, stride = 1, dropout = 0.0):\n",
        "    Initial = Input \n",
        "    x = BatchNormalization()(Input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0.0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(128*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    output = Add()([x,Initial])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4u2FV3y_wo8o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Creates Wide Residual network with given parameters\n",
        "\n",
        "height = height of the Image\n",
        "width = width of the Image\n",
        "K = Width of the network(will be multiplied)\n",
        "depth = No of convolutional layers\n",
        "\n",
        "\"\"\"\n",
        "def create_wide_residual_network(height,width,k,depth):\n",
        "    \n",
        "    n = (depth-4)/6\n",
        "    \n",
        "    #Input tensor\n",
        "    inputs = Input(shape = (height,width,3), name = \"image_input\")\n",
        "    \n",
        "    #Initial Conv block\n",
        "    x = initial_conv(inputs)\n",
        "    \n",
        "    #First Expansion block\n",
        "    x = expand_conv(x,k,1,1,0.3)\n",
        "    \n",
        "    #First Convolutional Block\n",
        "    #Depth depends on n\n",
        "    for i in range(n-1):\n",
        "        x = conv_block1(x,k,1,0.3)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    #Second Expansion Block\n",
        "    x = expand_conv(x,k,2,2,0.3)\n",
        "    \n",
        "    \n",
        "    #Second Convolutional Block\n",
        "    #Depth depends on n\n",
        "    for i in range(n-1):\n",
        "        x = conv_block2(x,k,1,0.3)\n",
        "        \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    \n",
        "    #Third Expansion Block\n",
        "    x = expand_conv(x,k,4,2,0.3)\n",
        "    \n",
        "    #Third Convolutional Block \n",
        "    #Depth depends on n\n",
        "    for i in range(n-1):\n",
        "        x = conv_block3(x,k,1,0.3)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    #Avg pooling to get 1*1 feature vectors\n",
        "    x = AveragePooling2D(pool_size=(8,8))(x)\n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    #Classification Layer\n",
        "    x = Dense(1,activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYd7sn28wwV1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_wide_residual_network(128,128,4,16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5E6H8519w9mT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2210
        },
        "outputId": "8227f288-bfe6-4663-98cd-3e14a7c6648b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523294086535,
          "user_tz": -330,
          "elapsed": 825,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image_input (InputLayer)        (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 128, 128, 16) 448         image_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 128, 128, 16) 64          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 128, 128, 16) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 128, 128, 128 18560       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 128, 128, 128 512         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 128, 128, 128 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 128, 128, 128 0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 128, 128, 128 147584      dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 128, 128, 128 18560       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 128, 128, 128 0           conv2d_51[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 128, 128, 128 512         add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 128, 128, 128 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 128, 128, 128 147584      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 128, 128, 128 512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 128, 128, 128 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 128, 128, 128 0           activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 128, 128, 128 147584      dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 128, 128, 128 0           conv2d_54[0][0]                  \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 128, 128, 128 512         add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 128, 128, 128 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 64, 64, 256)  295168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 64, 64, 256)  1024        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 64, 64, 256)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 64, 64, 256)  0           activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 64, 64, 256)  590080      dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 64, 64, 256)  295168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 64, 64, 256)  0           conv2d_56[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 64, 64, 256)  1024        add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 64, 64, 256)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 64, 64, 256)  590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 64, 64, 256)  1024        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 64, 64, 256)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 64, 64, 256)  0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 64, 64, 256)  590080      dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 64, 64, 256)  0           conv2d_59[0][0]                  \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 64, 64, 256)  1024        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 64, 64, 256)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 512)  1180160     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 512)  2048        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 512)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 32, 32, 512)  0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 32, 32, 512)  2359808     dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 32, 32, 512)  1180160     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 32, 32, 512)  0           conv2d_61[0][0]                  \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 512)  2048        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 512)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 32, 32, 512)  2359808     activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 512)  2048        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 512)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 32, 32, 512)  0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 32, 32, 512)  2359808     dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 32, 32, 512)  0           conv2d_64[0][0]                  \n",
            "                                                                 add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 512)  2048        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 512)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 4, 4, 512)    0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 8192)         0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            8193        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 12,303,233\n",
            "Trainable params: 12,296,033\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BvMJYTwwyvaD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3r9P9A8v0w_w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "        optimizer=\"Adam\",\n",
        "        metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkvVgi9001TB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('classification_log.csv')\n",
        "model_chekpoint = ModelCheckpoint(\"weights/model2\",monitor = 'val_loss',verbose = 1,save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BmWJzZgd1ERR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ps60hDk_1Oky",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3451
        },
        "outputId": "2f285d37-c51a-4ef7-a0c8-59ff60d52925",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523300310811,
          "user_tz": -330,
          "elapsed": 6218798,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,callbacks=[lr_reducer, csv_logger,model_chekpoint], class_weight = class_weights)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1599 samples, validate on 401 samples\n",
            "Epoch 1/50\n",
            "1599/1599 [==============================] - 132s 82ms/step - loss: 1.1581 - acc: 0.6854 - val_loss: 1.6028 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.60280, saving model to weights/model2\n",
            "Epoch 2/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0034 - acc: 0.6854 - val_loss: 0.6705 - val_acc: 0.6434\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.60280 to 0.67045, saving model to weights/model2\n",
            "Epoch 3/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0393 - acc: 0.6548 - val_loss: 0.8656 - val_acc: 0.6683\n",
            "\n",
            "Epoch 00003: val_loss did not improve\n",
            "Epoch 4/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9483 - acc: 0.7373 - val_loss: 0.7472 - val_acc: 0.6983\n",
            "\n",
            "Epoch 00004: val_loss did not improve\n",
            "Epoch 5/50\n",
            " 128/1599 [=>............................] - ETA: 1:45 - loss: 0.8812 - acc: 0.8047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9763 - acc: 0.7405 - val_loss: 0.8533 - val_acc: 0.6010\n",
            "\n",
            "Epoch 00005: val_loss did not improve\n",
            "Epoch 6/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9866 - acc: 0.6917 - val_loss: 0.6062 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.67045 to 0.60620, saving model to weights/model2\n",
            "Epoch 7/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9659 - acc: 0.6585 - val_loss: 0.9639 - val_acc: 0.7207\n",
            "\n",
            "Epoch 00007: val_loss did not improve\n",
            "Epoch 8/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9324 - acc: 0.6610 - val_loss: 0.9025 - val_acc: 0.4289\n",
            "\n",
            "Epoch 00008: val_loss did not improve\n",
            "Epoch 9/50\n",
            " 896/1599 [===============>..............] - ETA: 50s - loss: 0.8680 - acc: 0.7400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8650 - acc: 0.7311 - val_loss: 0.5356 - val_acc: 0.7581\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.60620 to 0.53565, saving model to weights/model2\n",
            "Epoch 10/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9015 - acc: 0.7186 - val_loss: 0.7912 - val_acc: 0.4963\n",
            "\n",
            "Epoch 00010: val_loss did not improve\n",
            "Epoch 11/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0185 - acc: 0.7305 - val_loss: 0.7141 - val_acc: 0.7182\n",
            "\n",
            "Epoch 00011: val_loss did not improve\n",
            "Epoch 12/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0921 - acc: 0.6929 - val_loss: 5.5778 - val_acc: 0.5137\n",
            "\n",
            "Epoch 00012: val_loss did not improve\n",
            "Epoch 13/50\n",
            " 864/1599 [===============>..............] - ETA: 52s - loss: 0.9055 - acc: 0.6736"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9537 - acc: 0.6760 - val_loss: 0.6362 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00013: val_loss did not improve\n",
            "Epoch 14/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8909 - acc: 0.7192 - val_loss: 0.6280 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00014: val_loss did not improve\n",
            "Epoch 15/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8914 - acc: 0.6973 - val_loss: 0.5517 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00015: val_loss did not improve\n",
            "Epoch 16/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8590 - acc: 0.7192 - val_loss: 0.6009 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00016: val_loss did not improve\n",
            "Epoch 17/50\n",
            "1216/1599 [=====================>........] - ETA: 27s - loss: 0.8098 - acc: 0.7393"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8395 - acc: 0.7298 - val_loss: 0.6118 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00017: val_loss did not improve\n",
            "Epoch 18/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8665 - acc: 0.7430 - val_loss: 0.5692 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00018: val_loss did not improve\n",
            "Epoch 19/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8152 - acc: 0.7192 - val_loss: 0.5851 - val_acc: 0.6758\n",
            "\n",
            "Epoch 00019: val_loss did not improve\n",
            "Epoch 20/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8215 - acc: 0.7273 - val_loss: 0.5838 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00020: val_loss did not improve\n",
            "Epoch 21/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.8353 - acc: 0.7131"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8159 - acc: 0.7255 - val_loss: 0.5565 - val_acc: 0.7357\n",
            "\n",
            "Epoch 00021: val_loss did not improve\n",
            "Epoch 22/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8373 - acc: 0.7292 - val_loss: 0.5472 - val_acc: 0.7282\n",
            "\n",
            "Epoch 00022: val_loss did not improve\n",
            "Epoch 23/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8229 - acc: 0.7336 - val_loss: 0.5418 - val_acc: 0.7431\n",
            "\n",
            "Epoch 00023: val_loss did not improve\n",
            "Epoch 24/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8092 - acc: 0.7330 - val_loss: 0.5397 - val_acc: 0.7282\n",
            "\n",
            "Epoch 00024: val_loss did not improve\n",
            "Epoch 25/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.8019 - acc: 0.7444"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7940 - acc: 0.7405 - val_loss: 0.5580 - val_acc: 0.7032\n",
            "\n",
            "Epoch 00025: val_loss did not improve\n",
            "Epoch 26/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7870 - acc: 0.7624 - val_loss: 0.5606 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00026: val_loss did not improve\n",
            "Epoch 27/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7828 - acc: 0.7361 - val_loss: 0.6082 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00027: val_loss did not improve\n",
            "Epoch 28/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7925 - acc: 0.7536 - val_loss: 0.5406 - val_acc: 0.7182\n",
            "\n",
            "Epoch 00028: val_loss did not improve\n",
            "Epoch 29/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.7524 - acc: 0.7644"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7775 - acc: 0.7661 - val_loss: 0.5680 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00029: val_loss did not improve\n",
            "Epoch 30/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7491 - acc: 0.7605 - val_loss: 0.5370 - val_acc: 0.7332\n",
            "\n",
            "Epoch 00030: val_loss did not improve\n",
            "Epoch 31/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7605 - acc: 0.7567 - val_loss: 0.5348 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.53565 to 0.53477, saving model to weights/model2\n",
            "Epoch 32/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7465 - acc: 0.7736 - val_loss: 0.5607 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00032: val_loss did not improve\n",
            "Epoch 33/50\n",
            "1056/1599 [==================>...........] - ETA: 38s - loss: 0.7231 - acc: 0.7547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7403 - acc: 0.7592 - val_loss: 0.5732 - val_acc: 0.6933\n",
            "\n",
            "Epoch 00033: val_loss did not improve\n",
            "Epoch 34/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7428 - acc: 0.7611 - val_loss: 0.5817 - val_acc: 0.6858\n",
            "\n",
            "Epoch 00034: val_loss did not improve\n",
            "Epoch 35/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7328 - acc: 0.7817 - val_loss: 0.5495 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00035: val_loss did not improve\n",
            "Epoch 36/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7243 - acc: 0.7742 - val_loss: 0.5517 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00036: val_loss did not improve\n",
            "Epoch 37/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.7156 - acc: 0.7780"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7333 - acc: 0.7598 - val_loss: 0.5311 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.53477 to 0.53105, saving model to weights/model2\n",
            "Epoch 38/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7232 - acc: 0.7755 - val_loss: 0.5159 - val_acc: 0.7431\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.53105 to 0.51589, saving model to weights/model2\n",
            "Epoch 39/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7242 - acc: 0.7742 - val_loss: 0.5638 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00039: val_loss did not improve\n",
            "Epoch 40/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6941 - acc: 0.7986 - val_loss: 0.5671 - val_acc: 0.6883\n",
            "\n",
            "Epoch 00040: val_loss did not improve\n",
            "Epoch 41/50\n",
            " 640/1599 [===========>..................] - ETA: 1:08 - loss: 0.7334 - acc: 0.7781"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7169 - acc: 0.7780 - val_loss: 0.5613 - val_acc: 0.6983\n",
            "\n",
            "Epoch 00041: val_loss did not improve\n",
            "Epoch 42/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7071 - acc: 0.7861 - val_loss: 0.5750 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00042: val_loss did not improve\n",
            "Epoch 43/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6982 - acc: 0.7824 - val_loss: 0.5987 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00043: val_loss did not improve\n",
            "Epoch 44/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6892 - acc: 0.7855 - val_loss: 0.5743 - val_acc: 0.6683\n",
            "\n",
            "Epoch 00044: val_loss did not improve\n",
            "Epoch 45/50\n",
            "1216/1599 [=====================>........] - ETA: 27s - loss: 0.6928 - acc: 0.7887"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6858 - acc: 0.7980 - val_loss: 0.5610 - val_acc: 0.6933\n",
            "\n",
            "Epoch 00045: val_loss did not improve\n",
            "Epoch 46/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6504 - acc: 0.8005 - val_loss: 0.5712 - val_acc: 0.6808\n",
            "\n",
            "Epoch 00046: val_loss did not improve\n",
            "Epoch 47/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6408 - acc: 0.8074 - val_loss: 0.5283 - val_acc: 0.7232\n",
            "\n",
            "Epoch 00047: val_loss did not improve\n",
            "Epoch 48/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6509 - acc: 0.8143 - val_loss: 0.5464 - val_acc: 0.7132\n",
            "\n",
            "Epoch 00048: val_loss did not improve\n",
            "Epoch 49/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.5989 - acc: 0.8197"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6303 - acc: 0.8043 - val_loss: 0.5781 - val_acc: 0.6783\n",
            "\n",
            "Epoch 00049: val_loss did not improve\n",
            "Epoch 50/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6275 - acc: 0.8099 - val_loss: 0.5641 - val_acc: 0.6958\n",
            "\n",
            "Epoch 00050: val_loss did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ea09a31d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "to_us401H4ic",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights/model2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zc1CebsnIGQr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QxPsjCI-IsSN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,name = \"Cf.png\",\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig = plt.gcf()\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    fig.savefig(name)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkK3tcFvI5Qx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "33587366-6c42-47ca-9b2a-c91985db20f2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523302370569,
          "user_tz": -330,
          "elapsed": 1039,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_names = ['Others', 'Melanoma']\n",
        "predictions = np.array(predictions)\n",
        "predictions_results = predictions >= 0.5\n",
        "cnf_matrix = confusion_matrix(y_test, predictions_results)\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,normalize= False,\n",
        "                      name = \"Confusion_matrix.png\",\n",
        "                      title='Confusion matrix')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[195 131]\n",
            " [ 33  42]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEmCAYAAAA9eGh/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEyVUEZGYKKGKiMTk/wEUSLvn5yU17AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7e9de72390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ohYUAAfpzXG1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}