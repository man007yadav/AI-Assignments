{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin-classification.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KhPbgerlhCvF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " !pip install -U -q PyDrive ## you will have install for every colab session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7XBkCJGhFkC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1KdpgwPhIYK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "json_import = drive.CreateFile({'id':'1ONFNFcwp81mhJmTvBa-cdr9rtbh6j-NF'})\n",
        "json_import.GetContentFile('y_train.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "json_import = drive.CreateFile({'id':'1BoBts1RcOjWrs9ZynAwW74MgEhjMREiZ'})\n",
        "json_import.GetContentFile('y_test.npy')\n",
        "y_test = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5pRbde2jMUb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "260cc240-7596-4fa6-cf1e-5617a51209a7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523291856622,
          "user_tz": -330,
          "elapsed": 1508,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.shape,y_test.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1599, 1), (401, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "lUX3vIzzhcVY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "json_import = drive.CreateFile({'id':'1xRSfGO8G25lQ_4-cANtWYkm4DbX6IV9_'})\n",
        "json_import.GetContentFile('X_train.npy')\n",
        "X_train = np.load('X_train.npy')\n",
        "json_import = drive.CreateFile({'id':'1TmJmYnPm__-OrWOZhbSVyXW4Uzo175L8'})\n",
        "json_import.GetContentFile('X_test.npy')\n",
        "X_test = np.load('X_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CuK-8Bn2jVRs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4700044e-ff25-4279-927f-8d4f8168ac47",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523291869707,
          "user_tz": -330,
          "elapsed": 1481,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1599, 128, 128, 3), (401, 128, 128, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "_RmA33rSjeTk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e2a3a42d-e6a8-48c6-a201-458c45193e18",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523282343573,
          "user_tz": -330,
          "elapsed": 10722,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6dc4daac-9d12-462b-bb8f-ada848c10521\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6dc4daac-9d12-462b-bb8f-ada848c10521\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving resnet_classifier_ISIC.py to resnet_classifier_ISIC.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-0jJFI_2kg75",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from keras.layers import Add\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint\n",
        "import scipy.io as scio\n",
        "import numpy as np    \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import re\n",
        "from scipy.misc import imsave\n",
        "from scipy.misc import imresize\n",
        "from scipy import ndimage, misc\n",
        "from numpy import unravel_index\n",
        "from operator import sub\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kemt0eV1wEHE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = X_train.astype('float32')\n",
        "x_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7mziW9nnwOwI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_Ts1BPNwUj7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def initial_conv(Input):\n",
        "    x = Conv2D(16,kernel_size=(3,3),strides = (1,1),padding = 'same')(Input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KSHChhdwZLt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def expand_conv(Input, k=1, conv_no = 1,stride=1,dropout =0.0):\n",
        "    Initial = Input\n",
        "    x = Conv2D(32*k*conv_no,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(Input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(32*k*conv_no,kernel_size=(3,3),strides = (1,1),padding ='same')(x)\n",
        "    skip = Conv2D(32*k*conv_no,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(Input)\n",
        "    output = Add()([x,skip])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6bUcO5AxJq0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block1(Input, k = 1, stride = 1, dropout = 0.0):\n",
        "    Initial = Input \n",
        "    x = BatchNormalization()(Input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(32*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0.0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(32*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    output = Add()([x,Initial])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ju8ig-Ldwgec",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block2(Input, k = 1, stride = 1, dropout = 0.0):\n",
        "    Initial = Input \n",
        "    x = BatchNormalization()(Input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0.0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(64*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    output = Add()([x,Initial])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gOkCtUIXwlR8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block3(Input, k = 1, stride = 1, dropout = 0.0):\n",
        "    Initial = Input \n",
        "    x = BatchNormalization()(Input)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if(dropout > 0.0):\n",
        "        x = Dropout(dropout)(x)\n",
        "    x = Conv2D(128*k,kernel_size=(3,3),strides = (stride,stride),padding = 'same')(x)\n",
        "    output = Add()([x,Initial])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4u2FV3y_wo8o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Creates Wide Residual network with given parameters\n",
        "\n",
        "height = height of the Image\n",
        "width = width of the Image\n",
        "K = Width of the network(will be multiplied)\n",
        "depth = No of convolutional layers\n",
        "\n",
        "\"\"\"\n",
        "def create_wide_residual_network(height,width,k,depth):\n",
        "    \n",
        "    n = (depth-4)/6\n",
        "    \n",
        "    #Input tensor\n",
        "    inputs = Input(shape = (height,width,3), name = \"image_input\")\n",
        "    \n",
        "    #Initial Conv block\n",
        "    x = initial_conv(inputs)\n",
        "    \n",
        "    #First Expansion block\n",
        "    x = expand_conv(x,k,1,1,0.3)\n",
        "    \n",
        "    #First Convolutional Block\n",
        "    #Depth depends on n\n",
        "    for i in range(n-1):\n",
        "        x = conv_block1(x,k,1,0.3)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    #Second Expansion Block\n",
        "    x = expand_conv(x,k,2,2,0.3)\n",
        "    \n",
        "    \n",
        "    #Second Convolutional Block\n",
        "    #Depth depends on n\n",
        "    for i in range(n-1):\n",
        "        x = conv_block2(x,k,1,0.3)\n",
        "        \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    \n",
        "    #Third Expansion Block\n",
        "    x = expand_conv(x,k,4,2,0.3)\n",
        "    \n",
        "    #Third Convolutional Block \n",
        "    #Depth depends on n\n",
        "    for i in range(n-1):\n",
        "        x = conv_block3(x,k,1,0.3)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    #Avg pooling to get 1*1 feature vectors\n",
        "    x = AveragePooling2D(pool_size=(8,8))(x)\n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    #Classification Layer\n",
        "    x = Dense(1,activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYd7sn28wwV1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = create_wide_residual_network(128,128,4,16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5E6H8519w9mT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2210
        },
        "outputId": "8227f288-bfe6-4663-98cd-3e14a7c6648b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523294086535,
          "user_tz": -330,
          "elapsed": 825,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image_input (InputLayer)        (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 128, 128, 16) 448         image_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 128, 128, 16) 64          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 128, 128, 16) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 128, 128, 128 18560       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 128, 128, 128 512         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 128, 128, 128 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 128, 128, 128 0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 128, 128, 128 147584      dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 128, 128, 128 18560       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 128, 128, 128 0           conv2d_51[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 128, 128, 128 512         add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 128, 128, 128 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 128, 128, 128 147584      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 128, 128, 128 512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 128, 128, 128 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 128, 128, 128 0           activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 128, 128, 128 147584      dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 128, 128, 128 0           conv2d_54[0][0]                  \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 128, 128, 128 512         add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 128, 128, 128 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 64, 64, 256)  295168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 64, 64, 256)  1024        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 64, 64, 256)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 64, 64, 256)  0           activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 64, 64, 256)  590080      dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 64, 64, 256)  295168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 64, 64, 256)  0           conv2d_56[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 64, 64, 256)  1024        add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 64, 64, 256)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 64, 64, 256)  590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 64, 64, 256)  1024        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 64, 64, 256)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 64, 64, 256)  0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 64, 64, 256)  590080      dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 64, 64, 256)  0           conv2d_59[0][0]                  \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 64, 64, 256)  1024        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 64, 64, 256)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 512)  1180160     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 512)  2048        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 512)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 32, 32, 512)  0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 32, 32, 512)  2359808     dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 32, 32, 512)  1180160     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 32, 32, 512)  0           conv2d_61[0][0]                  \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 512)  2048        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 512)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 32, 32, 512)  2359808     activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 512)  2048        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 512)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 32, 32, 512)  0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 32, 32, 512)  2359808     dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 32, 32, 512)  0           conv2d_64[0][0]                  \n",
            "                                                                 add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 512)  2048        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 512)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 4, 4, 512)    0           activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 8192)         0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            8193        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 12,303,233\n",
            "Trainable params: 12,296,033\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BvMJYTwwyvaD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3r9P9A8v0w_w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "        optimizer=\"Adam\",\n",
        "        metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkvVgi9001TB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
        "csv_logger = CSVLogger('classification_log.csv')\n",
        "model_chekpoint = ModelCheckpoint(\"weights/model2\",monitor = 'val_loss',verbose = 1,save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BmWJzZgd1ERR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ps60hDk_1Oky",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3451
        },
        "outputId": "2f285d37-c51a-4ef7-a0c8-59ff60d52925",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523300310811,
          "user_tz": -330,
          "elapsed": 6218798,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,callbacks=[lr_reducer, csv_logger,model_chekpoint], class_weight = class_weights)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1599 samples, validate on 401 samples\n",
            "Epoch 1/50\n",
            "1599/1599 [==============================] - 132s 82ms/step - loss: 1.1581 - acc: 0.6854 - val_loss: 1.6028 - val_acc: 0.4364\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.60280, saving model to weights/model2\n",
            "Epoch 2/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0034 - acc: 0.6854 - val_loss: 0.6705 - val_acc: 0.6434\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.60280 to 0.67045, saving model to weights/model2\n",
            "Epoch 3/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0393 - acc: 0.6548 - val_loss: 0.8656 - val_acc: 0.6683\n",
            "\n",
            "Epoch 00003: val_loss did not improve\n",
            "Epoch 4/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9483 - acc: 0.7373 - val_loss: 0.7472 - val_acc: 0.6983\n",
            "\n",
            "Epoch 00004: val_loss did not improve\n",
            "Epoch 5/50\n",
            " 128/1599 [=>............................] - ETA: 1:45 - loss: 0.8812 - acc: 0.8047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9763 - acc: 0.7405 - val_loss: 0.8533 - val_acc: 0.6010\n",
            "\n",
            "Epoch 00005: val_loss did not improve\n",
            "Epoch 6/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9866 - acc: 0.6917 - val_loss: 0.6062 - val_acc: 0.7506\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.67045 to 0.60620, saving model to weights/model2\n",
            "Epoch 7/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9659 - acc: 0.6585 - val_loss: 0.9639 - val_acc: 0.7207\n",
            "\n",
            "Epoch 00007: val_loss did not improve\n",
            "Epoch 8/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9324 - acc: 0.6610 - val_loss: 0.9025 - val_acc: 0.4289\n",
            "\n",
            "Epoch 00008: val_loss did not improve\n",
            "Epoch 9/50\n",
            " 896/1599 [===============>..............] - ETA: 50s - loss: 0.8680 - acc: 0.7400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8650 - acc: 0.7311 - val_loss: 0.5356 - val_acc: 0.7581\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.60620 to 0.53565, saving model to weights/model2\n",
            "Epoch 10/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9015 - acc: 0.7186 - val_loss: 0.7912 - val_acc: 0.4963\n",
            "\n",
            "Epoch 00010: val_loss did not improve\n",
            "Epoch 11/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0185 - acc: 0.7305 - val_loss: 0.7141 - val_acc: 0.7182\n",
            "\n",
            "Epoch 00011: val_loss did not improve\n",
            "Epoch 12/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 1.0921 - acc: 0.6929 - val_loss: 5.5778 - val_acc: 0.5137\n",
            "\n",
            "Epoch 00012: val_loss did not improve\n",
            "Epoch 13/50\n",
            " 864/1599 [===============>..............] - ETA: 52s - loss: 0.9055 - acc: 0.6736"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.9537 - acc: 0.6760 - val_loss: 0.6362 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00013: val_loss did not improve\n",
            "Epoch 14/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8909 - acc: 0.7192 - val_loss: 0.6280 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00014: val_loss did not improve\n",
            "Epoch 15/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8914 - acc: 0.6973 - val_loss: 0.5517 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00015: val_loss did not improve\n",
            "Epoch 16/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8590 - acc: 0.7192 - val_loss: 0.6009 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00016: val_loss did not improve\n",
            "Epoch 17/50\n",
            "1216/1599 [=====================>........] - ETA: 27s - loss: 0.8098 - acc: 0.7393"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8395 - acc: 0.7298 - val_loss: 0.6118 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00017: val_loss did not improve\n",
            "Epoch 18/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8665 - acc: 0.7430 - val_loss: 0.5692 - val_acc: 0.7406\n",
            "\n",
            "Epoch 00018: val_loss did not improve\n",
            "Epoch 19/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8152 - acc: 0.7192 - val_loss: 0.5851 - val_acc: 0.6758\n",
            "\n",
            "Epoch 00019: val_loss did not improve\n",
            "Epoch 20/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8215 - acc: 0.7273 - val_loss: 0.5838 - val_acc: 0.6608\n",
            "\n",
            "Epoch 00020: val_loss did not improve\n",
            "Epoch 21/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.8353 - acc: 0.7131"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8159 - acc: 0.7255 - val_loss: 0.5565 - val_acc: 0.7357\n",
            "\n",
            "Epoch 00021: val_loss did not improve\n",
            "Epoch 22/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8373 - acc: 0.7292 - val_loss: 0.5472 - val_acc: 0.7282\n",
            "\n",
            "Epoch 00022: val_loss did not improve\n",
            "Epoch 23/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.8229 - acc: 0.7336 - val_loss: 0.5418 - val_acc: 0.7431\n",
            "\n",
            "Epoch 00023: val_loss did not improve\n",
            "Epoch 24/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.8092 - acc: 0.7330 - val_loss: 0.5397 - val_acc: 0.7282\n",
            "\n",
            "Epoch 00024: val_loss did not improve\n",
            "Epoch 25/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.8019 - acc: 0.7444"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7940 - acc: 0.7405 - val_loss: 0.5580 - val_acc: 0.7032\n",
            "\n",
            "Epoch 00025: val_loss did not improve\n",
            "Epoch 26/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7870 - acc: 0.7624 - val_loss: 0.5606 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00026: val_loss did not improve\n",
            "Epoch 27/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7828 - acc: 0.7361 - val_loss: 0.6082 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00027: val_loss did not improve\n",
            "Epoch 28/50\n",
            "1599/1599 [==============================] - 124s 77ms/step - loss: 0.7925 - acc: 0.7536 - val_loss: 0.5406 - val_acc: 0.7182\n",
            "\n",
            "Epoch 00028: val_loss did not improve\n",
            "Epoch 29/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.7524 - acc: 0.7644"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7775 - acc: 0.7661 - val_loss: 0.5680 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00029: val_loss did not improve\n",
            "Epoch 30/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7491 - acc: 0.7605 - val_loss: 0.5370 - val_acc: 0.7332\n",
            "\n",
            "Epoch 00030: val_loss did not improve\n",
            "Epoch 31/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7605 - acc: 0.7567 - val_loss: 0.5348 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.53565 to 0.53477, saving model to weights/model2\n",
            "Epoch 32/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7465 - acc: 0.7736 - val_loss: 0.5607 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00032: val_loss did not improve\n",
            "Epoch 33/50\n",
            "1056/1599 [==================>...........] - ETA: 38s - loss: 0.7231 - acc: 0.7547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7403 - acc: 0.7592 - val_loss: 0.5732 - val_acc: 0.6933\n",
            "\n",
            "Epoch 00033: val_loss did not improve\n",
            "Epoch 34/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7428 - acc: 0.7611 - val_loss: 0.5817 - val_acc: 0.6858\n",
            "\n",
            "Epoch 00034: val_loss did not improve\n",
            "Epoch 35/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7328 - acc: 0.7817 - val_loss: 0.5495 - val_acc: 0.7082\n",
            "\n",
            "Epoch 00035: val_loss did not improve\n",
            "Epoch 36/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7243 - acc: 0.7742 - val_loss: 0.5517 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00036: val_loss did not improve\n",
            "Epoch 37/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.7156 - acc: 0.7780"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7333 - acc: 0.7598 - val_loss: 0.5311 - val_acc: 0.7481\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.53477 to 0.53105, saving model to weights/model2\n",
            "Epoch 38/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7232 - acc: 0.7755 - val_loss: 0.5159 - val_acc: 0.7431\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.53105 to 0.51589, saving model to weights/model2\n",
            "Epoch 39/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7242 - acc: 0.7742 - val_loss: 0.5638 - val_acc: 0.6833\n",
            "\n",
            "Epoch 00039: val_loss did not improve\n",
            "Epoch 40/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6941 - acc: 0.7986 - val_loss: 0.5671 - val_acc: 0.6883\n",
            "\n",
            "Epoch 00040: val_loss did not improve\n",
            "Epoch 41/50\n",
            " 640/1599 [===========>..................] - ETA: 1:08 - loss: 0.7334 - acc: 0.7781"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7169 - acc: 0.7780 - val_loss: 0.5613 - val_acc: 0.6983\n",
            "\n",
            "Epoch 00041: val_loss did not improve\n",
            "Epoch 42/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.7071 - acc: 0.7861 - val_loss: 0.5750 - val_acc: 0.7057\n",
            "\n",
            "Epoch 00042: val_loss did not improve\n",
            "Epoch 43/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6982 - acc: 0.7824 - val_loss: 0.5987 - val_acc: 0.6733\n",
            "\n",
            "Epoch 00043: val_loss did not improve\n",
            "Epoch 44/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6892 - acc: 0.7855 - val_loss: 0.5743 - val_acc: 0.6683\n",
            "\n",
            "Epoch 00044: val_loss did not improve\n",
            "Epoch 45/50\n",
            "1216/1599 [=====================>........] - ETA: 27s - loss: 0.6928 - acc: 0.7887"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6858 - acc: 0.7980 - val_loss: 0.5610 - val_acc: 0.6933\n",
            "\n",
            "Epoch 00045: val_loss did not improve\n",
            "Epoch 46/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6504 - acc: 0.8005 - val_loss: 0.5712 - val_acc: 0.6808\n",
            "\n",
            "Epoch 00046: val_loss did not improve\n",
            "Epoch 47/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6408 - acc: 0.8074 - val_loss: 0.5283 - val_acc: 0.7232\n",
            "\n",
            "Epoch 00047: val_loss did not improve\n",
            "Epoch 48/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6509 - acc: 0.8143 - val_loss: 0.5464 - val_acc: 0.7132\n",
            "\n",
            "Epoch 00048: val_loss did not improve\n",
            "Epoch 49/50\n",
            "1248/1599 [======================>.......] - ETA: 25s - loss: 0.5989 - acc: 0.8197"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6303 - acc: 0.8043 - val_loss: 0.5781 - val_acc: 0.6783\n",
            "\n",
            "Epoch 00049: val_loss did not improve\n",
            "Epoch 50/50\n",
            "1599/1599 [==============================] - 124s 78ms/step - loss: 0.6275 - acc: 0.8099 - val_loss: 0.5641 - val_acc: 0.6958\n",
            "\n",
            "Epoch 00050: val_loss did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ea09a31d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "to_us401H4ic",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('weights/model2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zc1CebsnIGQr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QxPsjCI-IsSN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,name = \"Cf.png\",\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig = plt.gcf()\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    fig.savefig(name)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkK3tcFvI5Qx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "e82eef0e-407d-4706-e374-4132a4e27a24",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523305521878,
          "user_tz": -330,
          "elapsed": 841,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class_names = ['Others', 'Melanoma']\n",
        "predictions = np.array(predictions)\n",
        "predictions_results = predictions >= 0.5\n",
        "cnf_matrix = confusion_matrix(y_test, predictions_results)\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,normalize= False,\n",
        "                      name = \"Confusion_matrix.png\",\n",
        "                      title='Confusion matrix')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[285  41]\n",
            " [ 28  47]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEmCAYAAAA9eGh/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMRECVVEJCZKqCIiMfn/mo7DJYc6hXsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7e9cc8af90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ohYUAAfpzXG1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "220aba87-8b18-4de7-9d86-78d6b2d4e37e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523305661634,
          "user_tz": -330,
          "elapsed": 812,
          "user": {
            "displayName": "Manoj Yadav",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110951547602098080724"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "f1_score(y_test,predictions_results)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5766871165644173"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "metadata": {
        "id": "cT3X4yPlDtbM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}